{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Week 2: Numerical Python (NumPy)**\n",
        "\n",
        "This week we introduce NumPy, the foundation of scientific computing in Python. By the end of this session, you'll understand why NumPy exists, how to work with arrays, and—most excitingly—you'll build a linear regression algorithm from scratch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **What We'll Learn Today**\n",
        "\n",
        "1. **Why NumPy matters** — speed and memory efficiency\n",
        "2. **Creating and inspecting arrays** — the core NumPy data structure\n",
        "3. **Indexing and slicing** — accessing and modifying array elements\n",
        "4. **Operations on arrays** — vectorised computation without loops\n",
        "5. **Boolean indexing** — filtering data with conditions\n",
        "6. **Broadcasting basics** — how NumPy handles different-shaped arrays\n",
        "7. **Building linear regression from scratch** — applying everything we've learned\n",
        "\n",
        "---\n",
        "\n",
        "### **How This Connects**\n",
        "\n",
        "NumPy is the backbone of Python's data science ecosystem:\n",
        "\n",
        "```\n",
        "Week 1: Python fundamentals\n",
        "    ↓\n",
        "Week 2: NumPy (arrays, vectorisation)  ← YOU ARE HERE\n",
        "    ↓\n",
        "Week 3: Pandas (built on NumPy)\n",
        "    ↓\n",
        "Week 6: scikit-learn (uses NumPy arrays)\n",
        "    ↓\n",
        "Week 8: PyTorch (tensors ≈ NumPy arrays on GPU)\n",
        "```\n",
        "\n",
        "The array manipulation skills you learn today will transfer directly to every subsequent week."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np  # Standard alias - you'll see this everywhere"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# **1. Why NumPy?**\n",
        "\n",
        "Python lists are flexible but slow for numerical work. NumPy arrays are:\n",
        "\n",
        "- **Fast**: Operations run in optimised C code, not Python loops\n",
        "- **Memory-efficient**: Fixed types mean no per-element overhead\n",
        "- **Convenient**: Vectorised operations replace explicit loops\n",
        "\n",
        "### **Speed Comparison**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a list and an array with 1 million elements\n",
        "python_list = list(range(1_000_000))\n",
        "numpy_array = np.arange(1_000_000)\n",
        "\n",
        "# Time: multiply each element by 2\n",
        "print(\"Python list:\")\n",
        "%timeit [x * 2 for x in python_list]\n",
        "\n",
        "print(\"\\nNumPy array:\")\n",
        "%timeit numpy_array * 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NumPy is typically **50-100x faster** for numerical operations. This matters when you're working with real datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# **2. Creating and Inspecting Arrays**\n",
        "\n",
        "The `ndarray` (n-dimensional array) is NumPy's core data structure.\n",
        "\n",
        "### **Creating Arrays**\n",
        "\n",
        "| Method | Description | Example |\n",
        "|--------|-------------|---------|\n",
        "| `np.array(list)` | From a Python list | `np.array([1, 2, 3])` |\n",
        "| `np.arange(n)` | Integers 0 to n-1 | `np.arange(5)` → [0,1,2,3,4] |\n",
        "| `np.arange(a, b, step)` | Range with step | `np.arange(0, 10, 2)` → [0,2,4,6,8] |\n",
        "| `np.zeros(shape)` | Array of zeros | `np.zeros((2, 3))` |\n",
        "| `np.ones(shape)` | Array of ones | `np.ones((3, 3))` |\n",
        "| `np.full(shape, value)` | Array of constant | `np.full((2, 2), 7)` |\n",
        "| `np.linspace(a, b, n)` | n evenly spaced values | `np.linspace(0, 1, 5)` |\n",
        "| `np.random.rand(shape)` | Random uniform [0,1) | `np.random.rand(3, 3)` |\n",
        "| `np.random.randn(shape)` | Random normal (μ=0, σ=1) | `np.random.randn(100)` |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# From a list\n",
        "arr = np.array([1, 2, 3, 4, 5])\n",
        "print(\"From list:\", arr)\n",
        "\n",
        "# Using arange\n",
        "arr = np.arange(0, 10, 2)  # start, stop, step\n",
        "print(\"arange:\", arr)\n",
        "\n",
        "# Zeros and ones\n",
        "zeros = np.zeros((2, 3))  # 2 rows, 3 columns\n",
        "print(\"Zeros:\\n\", zeros)\n",
        "\n",
        "# Random values\n",
        "np.random.seed(42)  # For reproducibility\n",
        "random_arr = np.random.rand(3)  # 3 random values between 0 and 1\n",
        "print(\"Random:\", random_arr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Array Attributes**\n",
        "\n",
        "| Attribute | Description |\n",
        "|-----------|-------------|\n",
        "| `.shape` | Dimensions (rows, cols, ...) |\n",
        "| `.ndim` | Number of dimensions |\n",
        "| `.size` | Total number of elements |\n",
        "| `.dtype` | Data type of elements |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "arr = np.arange(12).reshape(3, 4)  # Reshape into 3 rows, 4 columns\n",
        "print(\"Array:\\n\", arr)\n",
        "print(f\"\\nShape: {arr.shape}\")   # (3, 4)\n",
        "print(f\"Dimensions: {arr.ndim}\") # 2\n",
        "print(f\"Size: {arr.size}\")       # 12\n",
        "print(f\"Data type: {arr.dtype}\") # int64"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### **Exercise 1: Creating Arrays**\n",
        "\n",
        "1. Create an array of even numbers from 0 to 20 (inclusive) using `np.arange()`\n",
        "2. Create a 4×4 array filled with the value 5\n",
        "3. Create an array of 10 random integers between 1 and 100 using `np.random.randint()`\n",
        "4. Print the shape and data type of each array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### YOUR CODE HERE ###\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ⭐ **Extra Exercise 1**\n",
        "\n",
        "Create a 5×5 identity matrix (1s on diagonal, 0s elsewhere) using `np.eye()`. Then create the same matrix manually using `np.zeros()` and array indexing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### YOUR CODE HERE ###\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# **3. Indexing and Slicing**\n",
        "\n",
        "Accessing array elements works similarly to Python lists, but extends naturally to multiple dimensions.\n",
        "\n",
        "### **1D Arrays**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "arr = np.array([10, 20, 30, 40, 50])\n",
        "\n",
        "print(arr[0])      # First element: 10\n",
        "print(arr[-1])     # Last element: 50\n",
        "print(arr[1:4])    # Elements 1-3: [20, 30, 40]\n",
        "print(arr[::2])    # Every second element: [10, 30, 50]\n",
        "print(arr[::-1])   # Reversed: [50, 40, 30, 20, 10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **2D Arrays**\n",
        "\n",
        "Use `array[row, column]` syntax. The colon `:` means \"all elements along this axis\".\n",
        "\n",
        "```\n",
        "array[row_index, col_index]     # Single element\n",
        "array[row_slice, col_slice]     # Subarray\n",
        "array[:, col_index]             # Entire column\n",
        "array[row_index, :]             # Entire row\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "arr = np.arange(12).reshape(3, 4)\n",
        "print(\"Array:\")\n",
        "print(arr)\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Single element: row 0, column 2\n",
        "print(\"arr[0, 2] =\", arr[0, 2])  # 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Entire row 1\n",
        "print(\"arr[1, :] =\", arr[1, :])  # [4, 5, 6, 7]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Entire column 2\n",
        "print(\"arr[:, 2] =\", arr[:, 2])  # [2, 6, 10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Subarray: rows 0-1, columns 1-2\n",
        "print(\"arr[0:2, 1:3] =\")\n",
        "print(arr[0:2, 1:3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **3D Arrays (Demonstration)**\n",
        "\n",
        "The same logic extends to higher dimensions. Think of a 3D array as a \"stack of matrices\". You'll encounter these in image processing (height × width × colour channels) and deep learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a 3D array: 2 matrices, each 3x4\n",
        "arr_3d = np.arange(24).reshape(2, 3, 4)\n",
        "print(\"Shape:\", arr_3d.shape)  # (2, 3, 4)\n",
        "print(\"\\n3D Array:\")\n",
        "print(arr_3d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# First matrix (index 0 along first dimension)\n",
        "print(\"First matrix arr_3d[0]:\")\n",
        "print(arr_3d[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Element at matrix 1, row 2, column 3\n",
        "print(\"arr_3d[1, 2, 3] =\", arr_3d[1, 2, 3])  # 23"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# All matrices, all rows, last column\n",
        "print(\"arr_3d[:, :, -1] =\")\n",
        "print(arr_3d[:, :, -1])  # Last column from each matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Important: Slices Are Views**\n",
        "\n",
        "When you slice an array, NumPy returns a *view* (not a copy). Modifying the slice modifies the original!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "arr = np.array([1, 2, 3, 4, 5])\n",
        "slice_view = arr[1:4]\n",
        "\n",
        "slice_view[0] = 999  # Modify the slice\n",
        "\n",
        "print(\"Original array:\", arr)  # [1, 999, 3, 4, 5] - also changed!\n",
        "\n",
        "# To get an independent copy:\n",
        "slice_copy = arr[1:4].copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### **Exercise 2: Indexing and Slicing**\n",
        "\n",
        "Given the following array:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = np.arange(1, 26).reshape(5, 5)\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Extract:\n",
        "1. The element in the 3rd row, 4th column\n",
        "2. The entire 2nd row\n",
        "3. The entire last column\n",
        "4. The 2×2 subarray from the bottom-right corner\n",
        "5. Every other row (rows 0, 2, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### YOUR CODE HERE ###\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ⭐ **Extra Exercise 2**\n",
        "\n",
        "Using the same `data` array:\n",
        "1. Extract the diagonal elements (hint: `np.diag()`)\n",
        "2. Reverse the order of rows\n",
        "3. Reverse the order of columns\n",
        "4. Reverse both rows and columns (rotate 180°)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### YOUR CODE HERE ###\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# **4. Operations on Arrays**\n",
        "\n",
        "NumPy's power comes from *vectorised* operations—applying functions to entire arrays without explicit loops.\n",
        "\n",
        "### **Arithmetic Operations**\n",
        "\n",
        "Operations are applied element-wise:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "a = np.array([1, 2, 3, 4])\n",
        "b = np.array([10, 20, 30, 40])\n",
        "\n",
        "print(\"a + b =\", a + b)       # Element-wise addition\n",
        "print(\"a * b =\", a * b)       # Element-wise multiplication\n",
        "print(\"a ** 2 =\", a ** 2)     # Square each element\n",
        "print(\"b / a =\", b / a)       # Element-wise division"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Aggregation Functions**\n",
        "\n",
        "| Function | Description | Example |\n",
        "|----------|-------------|---------|\n",
        "| `np.sum()` / `.sum()` | Sum of elements | `arr.sum()` |\n",
        "| `np.mean()` / `.mean()` | Arithmetic mean | `arr.mean()` |\n",
        "| `np.std()` / `.std()` | Standard deviation | `arr.std()` |\n",
        "| `np.min()` / `.min()` | Minimum value | `arr.min()` |\n",
        "| `np.max()` / `.max()` | Maximum value | `arr.max()` |\n",
        "| `np.argmin()` | Index of minimum | `arr.argmin()` |\n",
        "| `np.argmax()` | Index of maximum | `arr.argmax()` |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "arr = np.array([3, 1, 4, 1, 5, 9, 2, 6])\n",
        "\n",
        "print(f\"Sum: {arr.sum()}\")\n",
        "print(f\"Mean: {arr.mean()}\")\n",
        "print(f\"Std: {arr.std():.2f}\")\n",
        "print(f\"Min: {arr.min()} at index {arr.argmin()}\")\n",
        "print(f\"Max: {arr.max()} at index {arr.argmax()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **The `axis` Parameter**\n",
        "\n",
        "For 2D arrays, you can aggregate along rows or columns:\n",
        "\n",
        "- `axis=0`: Operate *down* rows (collapse rows → one value per column)\n",
        "- `axis=1`: Operate *across* columns (collapse columns → one value per row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "arr = np.array([[1, 2, 3],\n",
        "                [4, 5, 6]])\n",
        "\n",
        "print(\"Array:\")\n",
        "print(arr)\n",
        "print(f\"\\nSum all: {arr.sum()}\")\n",
        "print(f\"Sum axis=0 (down columns): {arr.sum(axis=0)}\")  # [5, 7, 9]\n",
        "print(f\"Sum axis=1 (across rows): {arr.sum(axis=1)}\")   # [6, 15]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### **Exercise 3: Array Operations**\n",
        "\n",
        "Given poll data from 5 regions over 4 weeks:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Rows = regions, Columns = weeks\n",
        "np.random.seed(42)\n",
        "polls = np.random.randint(35, 65, size=(5, 4))\n",
        "print(\"Poll data (rows=regions, cols=weeks):\")\n",
        "print(polls)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Calculate:\n",
        "1. The overall average across all polls\n",
        "2. The average for each region (across all weeks)\n",
        "3. The average for each week (across all regions)\n",
        "4. Which region has the highest average support?\n",
        "5. Which week had the lowest overall support?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### YOUR CODE HERE ###\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# **5. Boolean Indexing**\n",
        "\n",
        "You can filter arrays using boolean conditions. The result is a new array containing only elements where the condition is `True`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "arr = np.array([1, 5, 3, 8, 2, 9, 4, 7])\n",
        "\n",
        "# Create a boolean mask\n",
        "mask = arr > 5\n",
        "print(\"Mask (arr > 5):\", mask)\n",
        "\n",
        "# Apply the mask\n",
        "print(\"Elements > 5:\", arr[mask])\n",
        "\n",
        "# Or directly:\n",
        "print(\"Elements > 5:\", arr[arr > 5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Combining Conditions**\n",
        "\n",
        "Use `&` (and), `|` (or), `~` (not). **Parentheses are required!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Elements between 3 and 7 (inclusive)\n",
        "print(\"3 <= x <= 7:\", arr[(arr >= 3) & (arr <= 7)])\n",
        "\n",
        "# Elements less than 3 OR greater than 7\n",
        "print(\"x < 3 or x > 7:\", arr[(arr < 3) | (arr > 7)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Modifying with Boolean Indexing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "arr = np.array([1, 5, 3, 8, 2, 9, 4, 7])\n",
        "\n",
        "# Set all values > 5 to 0\n",
        "arr[arr > 5] = 0\n",
        "print(\"After setting >5 to 0:\", arr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### **Exercise 4: Boolean Indexing**\n",
        "\n",
        "Given voter turnout data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.random.seed(123)\n",
        "turnout = np.random.uniform(30, 85, size=20).round(1)\n",
        "print(\"Turnout percentages:\")\n",
        "print(turnout)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Find all districts with turnout above 60%\n",
        "2. Count how many districts have turnout below 50%\n",
        "3. Calculate the mean turnout for districts between 50% and 70%\n",
        "4. Replace all turnout values below 40% with `np.nan` (missing value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### YOUR CODE HERE ###\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# **6. Broadcasting Basics**\n",
        "\n",
        "Broadcasting is how NumPy handles operations between arrays of different shapes. The smaller array is \"stretched\" to match the larger one.\n",
        "\n",
        "### **Scalar Broadcasting**\n",
        "\n",
        "The simplest case: operating with a single number."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "arr = np.array([1, 2, 3, 4])\n",
        "\n",
        "# The scalar 10 is broadcast to [10, 10, 10, 10]\n",
        "print(\"arr + 10 =\", arr + 10)\n",
        "print(\"arr * 2 =\", arr * 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Array Broadcasting**\n",
        "\n",
        "A 1D array can be broadcast across a 2D array if dimensions are compatible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2D array: shape (3, 4)\n",
        "arr_2d = np.array([[1, 2, 3, 4],\n",
        "                   [5, 6, 7, 8],\n",
        "                   [9, 10, 11, 12]])\n",
        "\n",
        "# 1D array: shape (4,)\n",
        "row_vector = np.array([10, 20, 30, 40])\n",
        "\n",
        "# Broadcasting: row_vector is added to each row\n",
        "print(\"arr_2d + row_vector:\")\n",
        "print(arr_2d + row_vector)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Common use case**: Centering data by subtracting column means."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Center each column (subtract its mean)\n",
        "col_means = arr_2d.mean(axis=0)  # Mean of each column\n",
        "print(\"Column means:\", col_means)\n",
        "\n",
        "centered = arr_2d - col_means    # Broadcasting subtracts from each row\n",
        "print(\"\\nCentered array:\")\n",
        "print(centered)\n",
        "\n",
        "# Verify: column means are now ~0\n",
        "print(\"\\nNew column means:\", centered.mean(axis=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### **Exercise 5: Broadcasting**\n",
        "\n",
        "Given exam scores for 4 students across 3 subjects:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Rows = students, Columns = subjects (Math, English, Science)\n",
        "scores = np.array([[85, 90, 78],\n",
        "                   [92, 88, 95],\n",
        "                   [70, 75, 80],\n",
        "                   [88, 92, 85]])\n",
        "\n",
        "print(\"Scores (students × subjects):\")\n",
        "print(scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Calculate the mean score for each subject\n",
        "2. Center the scores by subtracting subject means (so each subject has mean 0)\n",
        "3. Normalise each student's scores so they sum to 100 (divide by row sum, multiply by 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### YOUR CODE HERE ###\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# **7. Building Linear Regression from Scratch**\n",
        "\n",
        "Now let's apply everything we've learned to build a real machine learning algorithm.\n",
        "\n",
        "## **The Big Picture**\n",
        "\n",
        "Linear regression finds the best line through data points. Given input `x`, we predict output `y` with:\n",
        "\n",
        "$$\\hat{y} = \\alpha + \\beta x$$\n",
        "\n",
        "Where:\n",
        "- $\\alpha$ (alpha) is the **intercept** (where the line crosses y-axis)\n",
        "- $\\beta$ (beta) is the **slope** (how much y changes per unit x)\n",
        "- $\\hat{y}$ (y-hat) is our **prediction**\n",
        "\n",
        "**Our goal**: Find the values of $\\alpha$ and $\\beta$ that make our predictions as close as possible to the true values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Key Concepts**\n",
        "\n",
        "### **Loss Function**\n",
        "\n",
        "How do we measure \"how wrong\" our predictions are? We use **Mean Squared Error (MSE)**:\n",
        "\n",
        "$$\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$$\n",
        "\n",
        "This is the average of squared differences between true values ($y$) and predictions ($\\hat{y}$). We square so that:\n",
        "- Positive and negative errors don't cancel out\n",
        "- Larger errors are penalised more heavily\n",
        "\n",
        "### **Gradient Descent**\n",
        "\n",
        "To minimise the loss, we:\n",
        "1. Start with random values for $\\alpha$ and $\\beta$\n",
        "2. Calculate how the loss changes if we adjust each parameter (the **gradient**)\n",
        "3. Update parameters in the direction that decreases loss\n",
        "4. Repeat until loss stops decreasing\n",
        "\n",
        "### **Learning Rate**\n",
        "\n",
        "The **learning rate** controls how big a step we take each iteration:\n",
        "- Too large → we overshoot and never converge\n",
        "- Too small → learning is very slow\n",
        "- Just right → steady decrease in loss\n",
        "\n",
        "### **Epochs**\n",
        "\n",
        "One **epoch** is one complete pass through the update process. We typically run many epochs until convergence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## **Let's Build It Step by Step**\n",
        "\n",
        "### **Exercise 6a: Generate Fake Data**\n",
        "\n",
        "First, we'll create synthetic data where we *know* the true relationship.\n",
        "\n",
        "Generate:\n",
        "- 100 random `x` values between 0 and 10\n",
        "- True parameters: `alpha_true = 2.5`, `beta_true = 1.8`\n",
        "- `y` values using: $y = \\alpha + \\beta x + \\text{noise}$\n",
        "- Add random noise from a normal distribution (mean=0, std=1)\n",
        "\n",
        "Then plot the data using matplotlib."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "# True parameters (we'll try to recover these!)\n",
        "alpha_true = 2.5\n",
        "beta_true = 1.8\n",
        "\n",
        "### YOUR CODE HERE ###\n",
        "# 1. Generate 100 random x values between 0 and 10\n",
        "x = None  # Replace with your code\n",
        "\n",
        "# 2. Generate noise from normal distribution\n",
        "noise = None  # Replace with your code\n",
        "\n",
        "# 3. Calculate y = alpha + beta*x + noise\n",
        "y = None  # Replace with your code\n",
        "\n",
        "# 4. Plot the data\n",
        "# plt.scatter(x, y)\n",
        "# plt.xlabel('x')\n",
        "# plt.ylabel('y')\n",
        "# plt.title('Our Synthetic Data')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### **Exercise 6b: Prediction Function**\n",
        "\n",
        "Write a function that makes predictions given `x`, `alpha`, and `beta`.\n",
        "\n",
        "$$\\hat{y} = \\alpha + \\beta x$$\n",
        "\n",
        "Then test it with random initial guesses and see how far off the predictions are."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict(x, alpha, beta):\n",
        "    \"\"\"\n",
        "    Make predictions using linear model.\n",
        "    \n",
        "    Parameters:\n",
        "        x: array of input values\n",
        "        alpha: intercept\n",
        "        beta: slope\n",
        "    \n",
        "    Returns:\n",
        "        y_pred: array of predictions\n",
        "    \"\"\"\n",
        "    ### YOUR CODE HERE ###\n",
        "    pass  # Replace with your code\n",
        "\n",
        "\n",
        "# Test with random initial guesses\n",
        "alpha_guess = np.random.uniform(0, 5)\n",
        "beta_guess = np.random.uniform(0, 5)\n",
        "print(f\"Initial guesses: alpha={alpha_guess:.2f}, beta={beta_guess:.2f}\")\n",
        "print(f\"True values: alpha={alpha_true}, beta={beta_true}\")\n",
        "\n",
        "# Make predictions with our guesses\n",
        "y_pred = predict(x, alpha_guess, beta_guess)\n",
        "\n",
        "# Plot true data and our initial prediction line\n",
        "# plt.scatter(x, y, alpha=0.5, label='True data')\n",
        "# plt.scatter(x, y_pred, alpha=0.5, label='Predictions', color='red')\n",
        "# plt.legend()\n",
        "# plt.title('Our Predictions vs True Data (Before Training)')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### **Exercise 6c: Loss Function (MSE)**\n",
        "\n",
        "Write a function to compute Mean Squared Error:\n",
        "\n",
        "$$\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$$\n",
        "\n",
        "Use NumPy operations—no loops needed!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_mse(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Compute Mean Squared Error.\n",
        "    \n",
        "    Parameters:\n",
        "        y_true: array of true values\n",
        "        y_pred: array of predicted values\n",
        "    \n",
        "    Returns:\n",
        "        mse: mean squared error (single number)\n",
        "    \"\"\"\n",
        "    ### YOUR CODE HERE ###\n",
        "    # Hint: (y_true - y_pred) gives the errors\n",
        "\n",
        "    pass  # Replace with your code\n",
        "\n",
        "\n",
        "# Test: compute loss with our initial guesses\n",
        "y_pred = predict(x, alpha_guess, beta_guess)\n",
        "initial_loss = compute_mse(y, y_pred)\n",
        "print(f\"Initial MSE: {initial_loss:.2f}\")\n",
        "\n",
        "# Compare: what if we knew the true parameters?\n",
        "y_pred_true = predict(x, alpha_true, beta_true)\n",
        "true_loss = compute_mse(y, y_pred_true)\n",
        "print(f\"MSE with true parameters: {true_loss:.2f}\")\n",
        "print(f\"(This isn't zero because of noise in the data)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### **Exercise 6d: Computing Gradients**\n",
        "\n",
        "To update our parameters, we need to know: *\"If I increase alpha (or beta) slightly, does the loss go up or down?\"*\n",
        "\n",
        "The **gradient** tells us the direction and magnitude of change.\n",
        "\n",
        "For MSE with linear regression, the gradients are:\n",
        "\n",
        "$$\\frac{\\partial \\text{MSE}}{\\partial \\alpha} = \\frac{2}{n} \\sum (\\hat{y}_i - y_i) = \\text{mean}(\\text{error}) \\times 2$$\n",
        "\n",
        "$$\\frac{\\partial \\text{MSE}}{\\partial \\beta} = \\frac{2}{n} \\sum (\\hat{y}_i - y_i) \\cdot x_i = \\text{mean}(\\text{error} \\times x) \\times 2$$\n",
        "\n",
        "**Why these formulas?** These come from calculus (taking partial derivatives), but intuitively:\n",
        "- The gradient for $\\alpha$ is proportional to the average error (if we're overshooting on average, decrease $\\alpha$)\n",
        "- The gradient for $\\beta$ weights errors by the input value (if errors are larger for larger x, adjust the slope)\n",
        "\n",
        "Write a function that computes both gradients."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_gradients(x, y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Compute gradients for alpha and beta.\n",
        "    \n",
        "    Parameters:\n",
        "        x: input values\n",
        "        y_true: true output values\n",
        "        y_pred: predicted values\n",
        "    \n",
        "    Returns:\n",
        "        grad_alpha: gradient for alpha\n",
        "        grad_beta: gradient for beta\n",
        "    \"\"\"\n",
        "    n = len(y_true)\n",
        "    \n",
        "    ### YOUR CODE HERE ###\n",
        "    # 1. Compute errors: (y_pred - y_true)\n",
        "    errors = None  # Replace\n",
        "    \n",
        "    # 2. Gradient for alpha: (2/n) * sum of errors\n",
        "    grad_alpha = None  # Replace\n",
        "    \n",
        "    # 3. Gradient for beta: (2/n) * sum of (errors * x)\n",
        "    grad_beta = None  # Replace\n",
        "    \n",
        "    return grad_alpha, grad_beta\n",
        "\n",
        "\n",
        "# Test\n",
        "y_pred = predict(x, alpha_guess, beta_guess)\n",
        "grad_a, grad_b = compute_gradients(x, y, y_pred)\n",
        "print(f\"Gradient for alpha: {grad_a:.4f}\")\n",
        "print(f\"Gradient for beta: {grad_b:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### **Exercise 6e: The Training Loop**\n",
        "\n",
        "Now put it all together! The training loop:\n",
        "\n",
        "1. Make predictions with current alpha, beta\n",
        "2. Compute the loss\n",
        "3. Compute gradients\n",
        "4. Update parameters: `alpha = alpha - learning_rate * grad_alpha`\n",
        "5. Repeat for many epochs\n",
        "\n",
        "The update rule moves parameters in the *opposite* direction of the gradient (because gradient points toward increasing loss, and we want to decrease it).\n",
        "\n",
        "Write the complete `train_regression` function and run it!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_regression(x, y, epochs=100, learning_rate=0.01):\n",
        "    \"\"\"\n",
        "    Train a linear regression model using gradient descent.\n",
        "    \n",
        "    Parameters:\n",
        "        x: input values\n",
        "        y: true output values\n",
        "        epochs: number of training iterations\n",
        "        learning_rate: step size for parameter updates\n",
        "    \n",
        "    Returns:\n",
        "        alpha: learned intercept\n",
        "        beta: learned slope\n",
        "        loss_history: list of MSE values during training\n",
        "    \"\"\"\n",
        "    # Initialise parameters randomly\n",
        "    alpha = np.random.uniform(0, 1)\n",
        "    beta = np.random.uniform(0, 1)\n",
        "    \n",
        "    # Track loss over time\n",
        "    loss_history = []\n",
        "    \n",
        "    ### YOUR CODE HERE ###\n",
        "    for epoch in range(epochs):\n",
        "        # 1. Make predictions\n",
        "        y_pred = None  # Replace\n",
        "        \n",
        "        # 2. Compute and store loss\n",
        "        loss = None  # Replace\n",
        "        loss_history.append(loss)\n",
        "        \n",
        "        # 3. Compute gradients\n",
        "        grad_alpha, grad_beta = None, None  # Replace\n",
        "        \n",
        "        # 4. Update parameters (subtract gradient * learning_rate)\n",
        "        alpha = None  # Replace\n",
        "        beta = None   # Replace\n",
        "        \n",
        "        # Optional: print progress every 20 epochs\n",
        "        if epoch % 20 == 0:\n",
        "            print(f\"Epoch {epoch}: Loss = {loss:.4f}, alpha = {alpha:.4f}, beta = {beta:.4f}\")\n",
        "    \n",
        "    return alpha, beta, loss_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the model!\n",
        "np.random.seed(42)  # For reproducibility\n",
        "\n",
        "alpha_learned, beta_learned, losses = train_regression(\n",
        "    x, y, \n",
        "    epochs=100, \n",
        "    learning_rate=0.01\n",
        ")\n",
        "\n",
        "print(f\"\\nFinal results:\")\n",
        "print(f\"Learned: alpha = {alpha_learned:.4f}, beta = {beta_learned:.4f}\")\n",
        "print(f\"True:    alpha = {alpha_true}, beta = {beta_true}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot the loss curve\n",
        "plt.figure(figsize=(10, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(losses)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('MSE')\n",
        "plt.title('Loss During Training')\n",
        "\n",
        "# Plot the final fit\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(x, y, alpha=0.5, label='Data')\n",
        "x_line = np.linspace(0, 10, 100)\n",
        "y_line = predict(x_line, alpha_learned, beta_learned)\n",
        "plt.plot(x_line, y_line, color='red', linewidth=2, label='Learned line')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.title('Final Fit')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### **Exercise 6f: Experiment!**\n",
        "\n",
        "Now that you have a working model, experiment with the hyperparameters:\n",
        "\n",
        "1. **Learning rate too high**: Try `learning_rate=0.5`. What happens?\n",
        "2. **Learning rate too low**: Try `learning_rate=0.0001` with 100 epochs. Does it converge?\n",
        "3. **More epochs**: With `learning_rate=0.0001`, try 1000 epochs. Does it get closer to the true values?\n",
        "4. **Noisy data**: Regenerate data with `noise = np.random.randn(100) * 5` (5x more noise). Can the model still learn?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### YOUR EXPERIMENTS HERE ###\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### ⭐ **Extra Exercise 6: Multivariate Regression**\n",
        "\n",
        "Extend your regression to handle multiple input features:\n",
        "\n",
        "$$\\hat{y} = \\alpha + \\beta_1 x_1 + \\beta_2 x_2 + ... + \\beta_k x_k$$\n",
        "\n",
        "Or in matrix form: $\\hat{y} = X \\mathbf{\\beta}$ where $X$ includes a column of ones for the intercept.\n",
        "\n",
        "Hints:\n",
        "- Stack a column of ones with your features: `X_b = np.hstack([np.ones((n, 1)), X])`\n",
        "- Prediction: `y_pred = X_b @ betas` (matrix multiplication)\n",
        "- Gradient: `grad_betas = (2/n) * X_b.T @ (y_pred - y_true)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### YOUR CODE HERE ###\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# **Summary**\n",
        "\n",
        "Today you learned:\n",
        "\n",
        "| Concept | Key Functions |\n",
        "|---------|---------------|\n",
        "| Creating arrays | `np.array()`, `np.arange()`, `np.zeros()`, `np.random.rand()` |\n",
        "| Array attributes | `.shape`, `.ndim`, `.size`, `.dtype` |\n",
        "| Indexing/slicing | `arr[i, j]`, `arr[start:stop]`, `arr[:, col]` |\n",
        "| Operations | `+`, `-`, `*`, `/`, `**` (element-wise) |\n",
        "| Aggregations | `.sum()`, `.mean()`, `.std()`, `.min()`, `.max()` |\n",
        "| Boolean indexing | `arr[arr > 5]`, `arr[(cond1) & (cond2)]` |\n",
        "| Broadcasting | Scalar + array, row + matrix |\n",
        "\n",
        "And you built linear regression from scratch using gradient descent!\n",
        "\n",
        "---\n",
        "\n",
        "# **What's Next**\n",
        "\n",
        "**Week 3: Pandas** — A library built on NumPy for working with tabular data (like spreadsheets). You'll use many of the same concepts (indexing, boolean filtering, aggregations) but with labelled rows and columns.\n",
        "\n",
        "### **Homework**\n",
        "\n",
        "Complete the exercises in the `Homework_W2.ipynb` notebook, which has you solve problems from the [numpy-100](https://github.com/rougier/numpy-100) collection.\n",
        "\n",
        "### **Further Resources**\n",
        "\n",
        "- [NumPy Documentation](https://numpy.org/doc/stable/)\n",
        "- [NumPy: The Absolute Basics for Beginners](https://numpy.org/doc/stable/user/absolute_beginners.html)\n",
        "- McKinney, *Python for Data Analysis*, Chapter 4\n",
        "- VanderPlas, *Python Data Science Handbook*, Chapters 4-12"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# **Solutions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Solution: Exercise 1 - Creating Arrays\n",
        "\n",
        "# 1. Even numbers from 0 to 20\n",
        "evens = np.arange(0, 21, 2)\n",
        "print(\"Evens:\", evens)\n",
        "print(f\"Shape: {evens.shape}, dtype: {evens.dtype}\\n\")\n",
        "\n",
        "# 2. 4x4 array of 5s\n",
        "fives = np.full((4, 4), 5)\n",
        "print(\"4x4 of 5s:\")\n",
        "print(fives)\n",
        "print(f\"Shape: {fives.shape}, dtype: {fives.dtype}\\n\")\n",
        "\n",
        "# 3. 10 random integers between 1 and 100\n",
        "np.random.seed(42)\n",
        "rand_ints = np.random.randint(1, 101, size=10)\n",
        "print(\"Random integers:\", rand_ints)\n",
        "print(f\"Shape: {rand_ints.shape}, dtype: {rand_ints.dtype}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Solution: Exercise 2 - Indexing and Slicing\n",
        "\n",
        "data = np.arange(1, 26).reshape(5, 5)\n",
        "print(\"Original:\")\n",
        "print(data)\n",
        "print()\n",
        "\n",
        "# 1. Element in 3rd row, 4th column (0-indexed: row 2, col 3)\n",
        "print(\"1. data[2, 3] =\", data[2, 3])  # 14\n",
        "\n",
        "# 2. Entire 2nd row\n",
        "print(\"2. data[1, :] =\", data[1, :])  # [6, 7, 8, 9, 10]\n",
        "\n",
        "# 3. Last column\n",
        "print(\"3. data[:, -1] =\", data[:, -1])  # [5, 10, 15, 20, 25]\n",
        "\n",
        "# 4. 2x2 bottom-right corner\n",
        "print(\"4. data[-2:, -2:] =\")\n",
        "print(data[-2:, -2:])  # [[19, 20], [24, 25]]\n",
        "\n",
        "# 5. Every other row\n",
        "print(\"5. data[::2, :] =\")\n",
        "print(data[::2, :])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Solution: Exercise 3 - Array Operations\n",
        "\n",
        "np.random.seed(42)\n",
        "polls = np.random.randint(35, 65, size=(5, 4))\n",
        "print(\"Poll data:\")\n",
        "print(polls)\n",
        "print()\n",
        "\n",
        "# 1. Overall average\n",
        "print(f\"1. Overall average: {polls.mean():.2f}\")\n",
        "\n",
        "# 2. Average per region (across columns, so axis=1)\n",
        "print(f\"2. Average per region: {polls.mean(axis=1)}\")\n",
        "\n",
        "# 3. Average per week (down rows, so axis=0)\n",
        "print(f\"3. Average per week: {polls.mean(axis=0)}\")\n",
        "\n",
        "# 4. Region with highest average\n",
        "region_avgs = polls.mean(axis=1)\n",
        "print(f\"4. Highest average region: {region_avgs.argmax()} (avg: {region_avgs.max():.2f})\")\n",
        "\n",
        "# 5. Week with lowest support\n",
        "week_avgs = polls.mean(axis=0)\n",
        "print(f\"5. Lowest support week: {week_avgs.argmin()} (avg: {week_avgs.min():.2f})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Solution: Exercise 4 - Boolean Indexing\n",
        "\n",
        "np.random.seed(123)\n",
        "turnout = np.random.uniform(30, 85, size=20).round(1)\n",
        "print(\"Turnout:\", turnout)\n",
        "print()\n",
        "\n",
        "# 1. Districts with turnout above 60%\n",
        "print(\"1. Above 60%:\", turnout[turnout > 60])\n",
        "\n",
        "# 2. Count below 50%\n",
        "print(\"2. Count below 50%:\", (turnout < 50).sum())\n",
        "\n",
        "# 3. Mean turnout between 50% and 70%\n",
        "mask = (turnout >= 50) & (turnout <= 70)\n",
        "print(f\"3. Mean (50-70%): {turnout[mask].mean():.2f}\")\n",
        "\n",
        "# 4. Replace below 40% with NaN\n",
        "turnout_copy = turnout.copy()  # Don't modify original\n",
        "turnout_copy[turnout_copy < 40] = np.nan\n",
        "print(\"4. After replacing <40% with NaN:\", turnout_copy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Solution: Exercise 5 - Broadcasting\n",
        "\n",
        "scores = np.array([[85, 90, 78],\n",
        "                   [92, 88, 95],\n",
        "                   [70, 75, 80],\n",
        "                   [88, 92, 85]])\n",
        "print(\"Original scores:\")\n",
        "print(scores)\n",
        "print()\n",
        "\n",
        "# 1. Mean score for each subject\n",
        "subject_means = scores.mean(axis=0)\n",
        "print(\"1. Subject means:\", subject_means)\n",
        "\n",
        "# 2. Center by subject means\n",
        "centered = scores - subject_means\n",
        "print(\"\\n2. Centered scores:\")\n",
        "print(centered)\n",
        "print(\"Verification - new column means:\", centered.mean(axis=0))\n",
        "\n",
        "# 3. Normalise each student to sum to 100\n",
        "row_sums = scores.sum(axis=1, keepdims=True)  # keepdims for broadcasting\n",
        "normalised = scores / row_sums * 100\n",
        "print(\"\\n3. Normalised (rows sum to 100):\")\n",
        "print(normalised.round(2))\n",
        "print(\"Verification - row sums:\", normalised.sum(axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Solution: Exercise 6 (Complete Regression)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "# 6a: Generate data\n",
        "alpha_true = 2.5\n",
        "beta_true = 1.8\n",
        "x = np.random.uniform(0, 10, size=100)\n",
        "noise = np.random.randn(100)\n",
        "y = alpha_true + beta_true * x + noise\n",
        "\n",
        "# 6b: Prediction function\n",
        "def predict(x, alpha, beta):\n",
        "    return alpha + beta * x\n",
        "\n",
        "# 6c: Loss function\n",
        "def compute_mse(y_true, y_pred):\n",
        "    return ((y_true - y_pred) ** 2).mean()\n",
        "\n",
        "# 6d: Gradients\n",
        "def compute_gradients(x, y_true, y_pred):\n",
        "    n = len(y_true)\n",
        "    errors = y_pred - y_true\n",
        "    grad_alpha = (2 / n) * errors.sum()\n",
        "    grad_beta = (2 / n) * (errors * x).sum()\n",
        "    return grad_alpha, grad_beta\n",
        "\n",
        "# 6e: Training loop\n",
        "def train_regression(x, y, epochs=100, learning_rate=0.01):\n",
        "    alpha = np.random.uniform(0, 1)\n",
        "    beta = np.random.uniform(0, 1)\n",
        "    loss_history = []\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        y_pred = predict(x, alpha, beta)\n",
        "        loss = compute_mse(y, y_pred)\n",
        "        loss_history.append(loss)\n",
        "        grad_alpha, grad_beta = compute_gradients(x, y, y_pred)\n",
        "        alpha = alpha - learning_rate * grad_alpha\n",
        "        beta = beta - learning_rate * grad_beta\n",
        "        \n",
        "        if epoch % 20 == 0:\n",
        "            print(f\"Epoch {epoch}: Loss = {loss:.4f}, alpha = {alpha:.4f}, beta = {beta:.4f}\")\n",
        "    \n",
        "    return alpha, beta, loss_history\n",
        "\n",
        "# Train\n",
        "np.random.seed(42)\n",
        "alpha_learned, beta_learned, losses = train_regression(x, y, epochs=100, learning_rate=0.01)\n",
        "\n",
        "print(f\"\\nFinal: alpha = {alpha_learned:.4f}, beta = {beta_learned:.4f}\")\n",
        "print(f\"True:  alpha = {alpha_true}, beta = {beta_true}\")\n",
        "\n",
        "# Plot\n",
        "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
        "axes[0].plot(losses)\n",
        "axes[0].set_xlabel('Epoch')\n",
        "axes[0].set_ylabel('MSE')\n",
        "axes[0].set_title('Loss During Training')\n",
        "\n",
        "axes[1].scatter(x, y, alpha=0.5, label='Data')\n",
        "x_line = np.linspace(0, 10, 100)\n",
        "axes[1].plot(x_line, predict(x_line, alpha_learned, beta_learned), 'r-', lw=2, label='Fit')\n",
        "axes[1].set_xlabel('x')\n",
        "axes[1].set_ylabel('y')\n",
        "axes[1].legend()\n",
        "axes[1].set_title('Final Fit')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
